{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up a simple pipeline that writes the found items to a JSON file. \n",
    "* Assume each line contains one JSON element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('quoteresult.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the spider within scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotesSpider(scrapy.Spider):\n",
    "    name ='quotes'\n",
    "    allowed_domains = ['quotes.toscrape.com']\n",
    "    start_urls = ['http://quotes.toscrape.com/']\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL':logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline':1},\n",
    "        'FEED_FORMAT': 'json', \n",
    "        'FEED_URI': 'quoteresult.json' \n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.xpath('//div[@class=\"quote\"]'): \n",
    "            #response.css('div.quote'):\n",
    "            #yield {'text': quote.css('span.text::text').extract_first(),\n",
    "            #      'author': quote.css('span small:text').extract_first(),\n",
    "            #      'tags': quote.css('div.tags a.tag::text').extract()\n",
    "            yield {\n",
    "                'text': quote.xpath('./span[@class=\"text\"]/text()').extract_first(),\n",
    "                'author': quote.xpath('.//small[@class=\"author\"]/text()').extract_first(),\n",
    "                'tags': quote.xpath('.//div[@class=\"tags\"]/a[@class=\"tag\"]/text()').extract()\n",
    "            }\n",
    "\n",
    "        next_page_url = response.xpath('//li[@class=\"next\"]/a/@href').extract_first()\n",
    "        if next_page_url is not None:\n",
    "            yield scrapy.Request(response.urljoin(next_page_url))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-22 13:27:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2018-10-22 13:27:47 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2g  1 Mar 2016), cryptography 2.2.2, Platform Windows-10-10.0.16299-SP0\n",
      "2018-10-22 13:27:47 [scrapy.crawler] INFO: Overridden settings: {'FEED_FORMAT': 'json', 'FEED_URI': 'quoteresult.json', 'LOG_LEVEL': 30, 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x2bd64199940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(QuotesSpider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is E6F4-CD26\n",
      "\n",
      " Directory of C:\\Users\\ARADER\\GitHub\\swissarmy\\webscraping\n",
      "\n",
      "10/22/2018  01:26 PM    <DIR>          .\n",
      "10/22/2018  01:26 PM    <DIR>          ..\n",
      "10/22/2018  01:14 PM    <DIR>          .ipynb_checkpoints\n",
      "10/22/2018  01:27 PM            21,184 quoteresult.jl\n",
      "10/22/2018  01:27 PM            21,186 quoteresult.json\n",
      "10/22/2018  01:26 PM             8,257 ScrapyQuotesTest.ipynb\n",
      "               3 File(s)         50,627 bytes\n",
      "               3 Dir(s)  96,064,409,600 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                            tags  \\\n",
       "0  Albert Einstein        [change, deep-thoughts, thinking, world]   \n",
       "1     J.K. Rowling                            [abilities, choices]   \n",
       "2  Albert Einstein  [inspirational, life, live, miracle, miracles]   \n",
       "3      Jane Austen              [aliteracy, books, classic, humor]   \n",
       "4   Marilyn Monroe                    [be-yourself, inspirational]   \n",
       "\n",
       "                                                text  \n",
       "0  “The world as we have created it is a process ...  \n",
       "1  “It is our choices, Harry, that show what we t...  \n",
       "2  “There are only two ways to live your life. On...  \n",
       "3  “The person, be it gentleman or lady, who has ...  \n",
       "4  “Imperfection is beauty, madness is genius and...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('quoteresult.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeferredList at 0x2bd643c8780 current result: []>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
